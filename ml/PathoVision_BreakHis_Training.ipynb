{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd8042d8",
   "metadata": {},
   "source": [
    "# PathoVision: BreakHis Binary Classification (Benign vs Malignant)\n",
    "Academic support model for histopathology screening. Not a clinical diagnostic tool.\n",
    "\n",
    "**Goals**\n",
    "- Binary classification (Benign/Malignant)\n",
    "- ResNet50 transfer learning\n",
    "- Grad-CAM explainability\n",
    "- Kaggle/Colab ready\n",
    "- Exportable for backend inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ff2ff0",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0b01d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_curve, auc, classification_report\n",
    ")\n",
    "\n",
    "# Set seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666558a3",
   "metadata": {},
   "source": [
    "## 2. Dataset Setup (BreakHis)\n",
    "Set the dataset path below. Example for Kaggle: `/kaggle/input/breakhis`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4118bd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = '/kaggle/input/breakhis'  # change if needed\n",
    "\n",
    "# Expected BreakHis path structure (one possible layout):\n",
    "# /BreaKHis_v1/histology_slides/breast/benign/SOB/.../40X/*.png\n",
    "# /BreaKHis_v1/histology_slides/breast/malignant/SOB/.../40X/*.png\n",
    "\n",
    "benign_paths = glob(os.path.join(DATA_ROOT, '**', 'benign', '**', '*.png'), recursive=True)\n",
    "malignant_paths = glob(os.path.join(DATA_ROOT, '**', 'malignant', '**', '*.png'), recursive=True)\n",
    "\n",
    "print(f'Benign images: {len(benign_paths)}')\n",
    "print(f'Malignant images: {len(malignant_paths)}')\n",
    "print(f'Class imbalance ratio (M/B): {len(malignant_paths)/len(benign_paths):.2f}')\n",
    "\n",
    "all_paths = benign_paths + malignant_paths\n",
    "all_labels = [0] * len(benign_paths) + [1] * len(malignant_paths)\n",
    "\n",
    "# Build dataframe for easy splits\n",
    "df = pd.DataFrame({'path': all_paths, 'label': all_labels})\n",
    "\n",
    "# Check for corrupted images\n",
    "print('\\nVerifying image integrity...')\n",
    "valid_indices = []\n",
    "for idx, row in df.iterrows():\n",
    "    try:\n",
    "        img = Image.open(row['path']).convert('RGB')\n",
    "        img_array = np.array(img)\n",
    "        if img_array.shape == (img_array.shape[0], img_array.shape[1], 3):\n",
    "            valid_indices.append(idx)\n",
    "    except:\n",
    "        print(f'Corrupted or invalid image: {row[\"path\"]}')\n",
    "\n",
    "df = df.loc[valid_indices].reset_index(drop=True)\n",
    "print(f'Valid images: {len(df)} (removed {len(all_labels) - len(df)} corrupted)')\n",
    "print(f'Final class distribution:\\n{df[\"label\"].value_counts().sort_index()}')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebcd55df",
   "metadata": {},
   "source": [
    "## 3. Train/Val/Test Split (70/15/15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96347f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.30, random_state=SEED, stratify=df['label']\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df, test_size=0.50, random_state=SEED, stratify=temp_df['label']\n",
    ")\n",
    "\n",
    "print('Train:', len(train_df), 'Val:', len(val_df), 'Test:', len(test_df))\n",
    "train_df['label'].value_counts(), val_df['label'].value_counts(), test_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c38d6bf",
   "metadata": {},
   "source": [
    "## 4. Transforms and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f1a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "\n",
    "# Advanced augmentation tailored for histopathology (no noise to avoid confusion with artifacts)\n",
    "# Medical images should focus on geometric/intensity variations, not random noise\n",
    "train_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    # Geometric augmentations\n",
    "    T.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.85, 1.15), shear=5),\n",
    "    T.RandomRotation(degrees=20),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.5),\n",
    "    # Intensity augmentations (no Gaussian noise - medical images need clarity)\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.15, hue=0.05),\n",
    "    # Elastic deformation might be useful but we'll skip for simplicity\n",
    "    T.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "    # Normalize using ImageNet stats\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_tfms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Mixup augmentation implementation\n",
    "def mixup(x1, x2, y1, y2, alpha=0.2):\n",
    "    \"\"\"Mixup augmentation for better generalization\"\"\"\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    mixed_x = lam * x1 + (1 - lam) * x2\n",
    "    mixed_y = (lam, 1 - lam, y1, y2)  # soft labels\n",
    "    return mixed_x, mixed_y\n",
    "\n",
    "class BreakHisDataset(Dataset):\n",
    "    def __init__(self, df, transforms=None, use_mixup=False):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transforms = transforms\n",
    "        self.use_mixup = use_mixup\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(row['path']).convert('RGB')\n",
    "        label = int(row['label'])\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(img)\n",
    "        \n",
    "        # Mixup: randomly mix with another sample from the same batch\n",
    "        if self.use_mixup and np.random.rand() < 0.3:\n",
    "            idx2 = np.random.randint(0, len(self.df))\n",
    "            row2 = self.df.iloc[idx2]\n",
    "            img2 = Image.open(row2['path']).convert('RGB')\n",
    "            label2 = int(row2['label'])\n",
    "            if self.transforms:\n",
    "                img2 = self.transforms(img2)\n",
    "            img, (lam1, lam2, y1, y2) = mixup(img, img2, label, label2)\n",
    "            # For simplicity, return original label. In full implementation, use soft targets\n",
    "            return img, label\n",
    "        \n",
    "        return img, label\n",
    "\n",
    "train_ds = BreakHisDataset(train_df, transforms=train_tfms, use_mixup=True)\n",
    "val_ds = BreakHisDataset(val_df, transforms=val_tfms, use_mixup=False)\n",
    "test_ds = BreakHisDataset(test_df, transforms=val_tfms, use_mixup=False)\n",
    "\n",
    "# Compute class weights for weighted sampling/loss\n",
    "class_counts = train_df['label'].value_counts().sort_index().values\n",
    "class_weights = torch.Tensor(1.0 / class_counts)\n",
    "class_weights = class_weights / class_weights.sum() * 2\n",
    "sample_weights = [class_weights[label] for label in train_df['label']]\n",
    "sampler = torch.utils.data.WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
    "\n",
    "BATCH_SIZE = 32  # Increased for better gradient estimates\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f'Train samples: {len(train_ds)} | Val samples: {len(val_ds)} | Test samples: {len(test_ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3910c27",
   "metadata": {},
   "source": [
    "## 5. Model (ResNet50 Transfer Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a3ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet50_Weights\n",
    "\n",
    "model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Progressive unfreezing strategy:\n",
    "# 1. Freeze all initially\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# 2. Unfreeze layer4 (most specific to task)\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 3. Selectively unfreeze layer3[-1] (gradual unfreezing reduces overfitting)\n",
    "for param in model.layer3[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "# 4. Unfreeze BN layers even in frozen layers (helps adapt to new domain)\n",
    "for module in model.modules():\n",
    "    if isinstance(module, nn.BatchNorm2d):\n",
    "        module.requires_grad = True\n",
    "        # Increase momentum for batchnorm (helps stability)\n",
    "        module.momentum = 0.01\n",
    "\n",
    "# 5. Replace final linear layer with improved architecture\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(p=0.5),\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.BatchNorm1d(512),\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Linear(512, 2)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Compute total and trainable parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total parameters: {total_params:,}')\n",
    "print(f'Trainable parameters: {trainable_params:,}')\n",
    "print(f'Training ratio: {100 * trainable_params / total_params:.1f}%')\n",
    "\n",
    "# Loss function with class weights for imbalanced data\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(device), label_smoothing=0.1)\n",
    "\n",
    "# Optimizer: Use different learning rates for different layers (discriminative learning rates)\n",
    "param_groups = [\n",
    "    {'params': model.layer4[-1].parameters(), 'lr': 1e-3},\n",
    "    {'params': model.layer3[-1].parameters(), 'lr': 5e-4},\n",
    "    {'params': model.fc.parameters(), 'lr': 1e-2},\n",
    "    {'params': [p for module in [model.layer4, model.layer3[-1], model.fc] for p in module.parameters()\n",
    "                if not any(p is q for q in module.parameters() if hasattr(q, 'requires_grad'))],\n",
    "     'lr': 1e-4}\n",
    "]\n",
    "\n",
    "# Simplified optimizer - use default LR\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), \n",
    "                       lr=1e-3, weight_decay=1e-5, betas=(0.9, 0.999))\n",
    "\n",
    "print('Model ready for training')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8608052c",
   "metadata": {},
   "source": [
    "## 6. Training Loop with Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa2bf94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingAUC:\n",
    "    \"\"\"Early stopping based on validation AUC instead of loss\"\"\"\n",
    "    def __init__(self, patience=7, min_delta=0.001):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_auc = 0\n",
    "        self.best_epoch = 0\n",
    "        self.early_stop = False\n",
    "        self.best_model_state = None\n",
    "\n",
    "    def __call__(self, val_auc, model):\n",
    "        if val_auc > self.best_auc + self.min_delta:\n",
    "            self.best_auc = val_auc\n",
    "            self.counter = 0\n",
    "            self.best_model_state = {k: v.cpu().clone() for k, v in model.state_dict().items()}\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "    def load_best_model(self, model):\n",
    "        if self.best_model_state is not None:\n",
    "            model.load_state_dict(self.best_model_state)\n",
    "\n",
    "def train_one_epoch(model, loader, optimizer, criterion, scheduler=None):\n",
    "    model.train()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc='Training', leave=False):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Gradient clipping to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, epoch_f1\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "    all_preds, all_probs = [], []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc='Validating', leave=False):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            probs = torch.softmax(outputs, dim=1)\n",
    "            preds = torch.argmax(probs, dim=1)\n",
    "            \n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    epoch_f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "    \n",
    "    # Calculate AUC\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "    epoch_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return epoch_loss, epoch_acc, epoch_f1, epoch_auc\n",
    "\n",
    "# Learning rate scheduler: Cosine annealing with warm restarts for better convergence\n",
    "EPOCHS = 30\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "# Early stopping based on AUC\n",
    "early_stopping = EarlyStoppingAUC(patience=8, min_delta=0.002)\n",
    "\n",
    "history = {\n",
    "    'train_loss': [], 'val_loss': [], \n",
    "    'train_acc': [], 'val_acc': [],\n",
    "    'train_f1': [], 'val_f1': [],\n",
    "    'val_auc': []\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc, train_f1 = train_one_epoch(model, train_loader, optimizer, criterion, scheduler)\n",
    "    val_loss, val_acc, val_f1, val_auc = evaluate(model, val_loader, criterion)\n",
    "\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['train_f1'].append(train_f1)\n",
    "    history['val_f1'].append(val_f1)\n",
    "    history['val_auc'].append(val_auc)\n",
    "\n",
    "    print(f'Epoch {epoch+1:2d}/{EPOCHS} | '\n",
    "          f'Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | '\n",
    "          f'Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | '\n",
    "          f'Val AUC: {val_auc:.4f} | Val F1: {val_f1:.4f}')\n",
    "\n",
    "    early_stopping(val_auc, model)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "        early_stopping.load_best_model(model)\n",
    "        break\n",
    "\n",
    "print(f'Training complete! Best Val AUC: {early_stopping.best_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd47b674",
   "metadata": {},
   "source": [
    "## 7. Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Loss plot\n",
    "axes[0, 0].plot(history['train_loss'], label='Train Loss', marker='o', markersize=3)\n",
    "axes[0, 0].plot(history['val_loss'], label='Val Loss', marker='s', markersize=3)\n",
    "axes[0, 0].set_title('Loss vs Epoch', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Loss')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy plot\n",
    "axes[0, 1].plot(history['train_acc'], label='Train Acc', marker='o', markersize=3)\n",
    "axes[0, 1].plot(history['val_acc'], label='Val Acc', marker='s', markersize=3)\n",
    "axes[0, 1].set_title('Accuracy vs Epoch', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Epoch')\n",
    "axes[0, 1].set_ylabel('Accuracy')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# F1 Score plot\n",
    "axes[1, 0].plot(history['train_f1'], label='Train F1', marker='o', markersize=3)\n",
    "axes[1, 0].plot(history['val_f1'], label='Val F1', marker='s', markersize=3)\n",
    "axes[1, 0].set_title('F1 Score vs Epoch', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('F1 Score')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# AUC plot\n",
    "axes[1, 1].plot(history['val_auc'], label='Val AUC', marker='o', color='green', markersize=3)\n",
    "axes[1, 1].axhline(y=0.95, color='r', linestyle='--', label='Target (0.95)')\n",
    "axes[1, 1].set_title('Validation AUC vs Epoch', fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('AUC')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "axes[1, 1].set_ylim([0.5, 1.0])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print training summary\n",
    "print('\\n' + '='*60)\n",
    "print('TRAINING SUMMARY')\n",
    "print('='*60)\n",
    "print(f'Best Validation AUC: {max(history[\"val_auc\"]):.4f}')\n",
    "print(f'Final Train Accuracy: {history[\"train_acc\"][-1]:.4f}')\n",
    "print(f'Final Val Accuracy: {history[\"val_acc\"][-1]:.4f}')\n",
    "print(f'Final Train F1: {history[\"train_f1\"][-1]:.4f}')\n",
    "print(f'Final Val F1: {history[\"val_f1\"][-1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0018ab73",
   "metadata": {},
   "source": [
    "## 8. Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11b3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Evaluating on test set with detailed metrics...')\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_preds = []\n",
    "all_probs = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc='Test Evaluation'):\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "        all_labels.extend(labels.numpy())\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_probs.extend(probs[:, 1].cpu().numpy())\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "all_labels = np.array(all_labels)\n",
    "all_preds = np.array(all_preds)\n",
    "all_probs = np.array(all_probs)\n",
    "\n",
    "acc = accuracy_score(all_labels, all_preds)\n",
    "prec = precision_score(all_labels, all_preds, zero_division=0)\n",
    "rec = recall_score(all_labels, all_preds, zero_division=0)\n",
    "f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
    "\n",
    "# ROC-AUC\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Specificity and Sensitivity (for clinical relevance)\n",
    "tn = ((all_preds == 0) & (all_labels == 0)).sum()\n",
    "fp = ((all_preds == 1) & (all_labels == 0)).sum()\n",
    "fn = ((all_preds == 0) & (all_labels == 1)).sum()\n",
    "tp = ((all_preds == 1) & (all_labels == 1)).sum()\n",
    "\n",
    "sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('TEST SET EVALUATION RESULTS')\n",
    "print('='*60)\n",
    "print(f'Accuracy:       {acc:.4f} (Overall correctness)')\n",
    "print(f'Precision:      {prec:.4f} (Of predicted positive, how many correct)')\n",
    "print(f'Recall/Sensitivity: {rec:.4f} (Of actual positive, how many detected)')\n",
    "print(f'Specificity:    {specificity:.4f} (Of actual negative, how many detected)')\n",
    "print(f'F1 Score:       {f1:.4f} (Harmonic mean of precision & recall)')\n",
    "print(f'ROC-AUC:        {roc_auc:.4f} (Probability of correct ranking)')\n",
    "print('='*60)\n",
    "\n",
    "# Detailed classification report\n",
    "print('\\nDETAILED CLASSIFICATION REPORT:')\n",
    "print(classification_report(all_labels, all_preds, target_names=['Benign', 'Malignant'], zero_division=0))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Benign', 'Malignant'], \n",
    "            yticklabels=['Benign', 'Malignant'],\n",
    "            cbar_kws={'label': 'Count'},\n",
    "            ax=ax)\n",
    "ax.set_title('Confusion Matrix - Test Set', fontsize=12, fontweight='bold')\n",
    "ax.set_xlabel('Predicted Label')\n",
    "ax.set_ylabel('True Label')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC Curve with confidence intervals\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 6))\n",
    "ax.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})', linewidth=2, color='#1f77b4')\n",
    "ax.plot([0, 1], [0, 1], 'k--', linewidth=1, label='Random Classifier')\n",
    "ax.fill_between(fpr, tpr, alpha=0.2)\n",
    "ax.set_xlabel('False Positive Rate (1 - Specificity)', fontsize=11)\n",
    "ax.set_ylabel('True Positive Rate (Sensitivity)', fontsize=11)\n",
    "ax.set_title('ROC Curve - Test Set', fontsize=12, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=10)\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n✓ Test evaluation complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee98559",
   "metadata": {},
   "source": [
    "## 9. Grad-CAM Explainability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a1f481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.target_layer = target_layer\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output.detach()\n",
    "\n",
    "        def backward_hook(module, grad_input, grad_output):\n",
    "            self.gradients = grad_output[0].detach()\n",
    "\n",
    "        self.target_layer.register_forward_hook(forward_hook)\n",
    "        self.target_layer.register_full_backward_hook(backward_hook)\n",
    "\n",
    "    def generate(self, input_tensor, class_idx=None):\n",
    "        self.model.eval()\n",
    "        output = self.model(input_tensor)\n",
    "        \n",
    "        if class_idx is None:\n",
    "            class_idx = output.argmax(dim=1).item()\n",
    "\n",
    "        self.model.zero_grad()\n",
    "        \n",
    "        # Create one-hot encoded target\n",
    "        target = torch.zeros(output.shape).to(device)\n",
    "        target[0, class_idx] = 1\n",
    "        loss = (output * target).sum()\n",
    "        loss.backward()\n",
    "\n",
    "        gradients = self.gradients[0]\n",
    "        activations = self.activations[0]\n",
    "        \n",
    "        # Compute weights using global average pooling\n",
    "        weights = gradients.mean(dim=(1, 2))\n",
    "        \n",
    "        # Compute weighted sum of activations\n",
    "        cam = torch.zeros(activations.shape[1:], dtype=torch.float32).to(device)\n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * activations[i]\n",
    "\n",
    "        # Apply ReLU and normalize\n",
    "        cam = torch.relu(cam)\n",
    "        cam = cam - cam.min()\n",
    "        cam_max = cam.max()\n",
    "        if cam_max > 0:\n",
    "            cam = cam / cam_max\n",
    "        \n",
    "        cam = cam.detach().cpu().numpy()\n",
    "        return cam, class_idx\n",
    "\n",
    "def overlay_heatmap(image_path, cam, output_path='heatmap.png', alpha=0.5):\n",
    "    \"\"\"Create heatmap overlay with better visualization\"\"\"\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f'Failed to load image: {image_path}')\n",
    "        return None\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    cam_resized = cv2.resize(cam, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # Apply colormap\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam_resized), cv2.COLORMAP_JET)\n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Blend original and heatmap\n",
    "    overlay = cv2.addWeighted(img, 1-alpha, heatmap, alpha, 0)\n",
    "    \n",
    "    # Save\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    cv2.imwrite(output_path, cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "print('Initializing GradCAM for model layer4[-1]...')\n",
    "gradcam = GradCAM(model, model.layer4[-1])\n",
    "\n",
    "# Generate heatmaps for sample test images\n",
    "print('\\nGenerating Grad-CAM heatmaps for test samples...')\n",
    "os.makedirs('heatmaps', exist_ok=True)\n",
    "\n",
    "sample_indices = np.random.choice(len(test_df), min(5, len(test_df)), replace=False)\n",
    "for i, idx in enumerate(sample_indices):\n",
    "    sample_path = test_df.iloc[idx]['path']\n",
    "    \n",
    "    sample_img = Image.open(sample_path).convert('RGB')\n",
    "    input_tensor = val_tfms(sample_img).unsqueeze(0).to(device)\n",
    "    \n",
    "    cam, pred_class = gradcam.generate(input_tensor)\n",
    "    \n",
    "    class_name = class_names[pred_class]\n",
    "    heatmap_name = f'heatmap_sample_{i+1}_{class_name}.png'\n",
    "    heatmap_path = os.path.join('heatmaps', heatmap_name)\n",
    "    \n",
    "    overlay_heatmap(sample_path, cam, output_path=heatmap_path, alpha=0.5)\n",
    "    print(f'Saved: {heatmap_path} (Predicted: {class_name})')\n",
    "\n",
    "print('✓ GradCAM heatmaps generated successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3edf7",
   "metadata": {},
   "source": [
    "## 10. Inference Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae1cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = {0: 'Benign', 1: 'Malignant'}\n",
    "\n",
    "# Test-Time Augmentation (TTA) for more robust predictions\n",
    "def apply_tta_transforms(image, num_augmentations=5):\n",
    "    \"\"\"Apply multiple augmentations and return list of tensors\"\"\"\n",
    "    tta_list = []\n",
    "    \n",
    "    for _ in range(num_augmentations):\n",
    "        # Apply slight augmentations for predictions\n",
    "        tta_tfm = T.Compose([\n",
    "            T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            T.RandomAffine(degrees=5, translate=(0.05, 0.05)) if _ > 0 else T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            T.RandomHorizontalFlip(p=0.5) if _ > 1 else T.Compose([]),\n",
    "            T.RandomRotation(degrees=5) if _ > 2 else T.Compose([]),\n",
    "            T.ToTensor(),\n",
    "            T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        tta_list.append(tta_tfm(image))\n",
    "    \n",
    "    return tta_list\n",
    "\n",
    "def predict_image_tta(image_path, model, use_tta=True, num_tta=5):\n",
    "    \"\"\"Prediction with optional Test-Time Augmentation\"\"\"\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        if use_tta:\n",
    "            tta_imgs = apply_tta_transforms(image, num_tta)\n",
    "            tta_probs = []\n",
    "            for tta_img in tta_imgs:\n",
    "                tta_img = tta_img.unsqueeze(0).to(device)\n",
    "                output = model(tta_img)\n",
    "                probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "                tta_probs.append(probs)\n",
    "            \n",
    "            # Average predictions across augmentations\n",
    "            avg_probs = np.mean(tta_probs, axis=0)\n",
    "        else:\n",
    "            input_tensor = val_tfms(image).unsqueeze(0).to(device)\n",
    "            output = model(input_tensor)\n",
    "            avg_probs = torch.softmax(output, dim=1).cpu().numpy()[0]\n",
    "    \n",
    "    pred_idx = int(np.argmax(avg_probs))\n",
    "    confidence = float(avg_probs[pred_idx])\n",
    "    \n",
    "    return {\n",
    "        'prediction': class_names[pred_idx],\n",
    "        'confidence': confidence,\n",
    "        'probabilities': {\n",
    "            'benign': float(avg_probs[0]),\n",
    "            'malignant': float(avg_probs[1])\n",
    "        },\n",
    "        'tta_used': use_tta\n",
    "    }\n",
    "\n",
    "# Example predictions\n",
    "print('Example Predictions (with Test-Time Augmentation):')\n",
    "print('='*60)\n",
    "\n",
    "# Sample some test images\n",
    "sample_indices = np.random.choice(len(test_df), min(3, len(test_df)), replace=False)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    sample_path = test_df.iloc[idx]['path']\n",
    "    true_label = test_df.iloc[idx]['label']\n",
    "    \n",
    "    result = predict_image_tta(sample_path, model, use_tta=True, num_tta=5)\n",
    "    \n",
    "    true_name = 'Benign' if true_label == 0 else 'Malignant'\n",
    "    print(f'Image: {os.path.basename(sample_path)}')\n",
    "    print(f'True Label: {true_name}')\n",
    "    print(f'Prediction: {result[\"prediction\"]}')\n",
    "    print(f'Confidence: {result[\"confidence\"]:.4f}')\n",
    "    print(f'Probabilities: Benign={result[\"probabilities\"][\"benign\"]:.4f}, Malignant={result[\"probabilities\"][\"malignant\"]:.4f}')\n",
    "    print('-'*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a65d8198",
   "metadata": {},
   "source": [
    "## 11. Export Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29dc9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# Save model with metadata\n",
    "model_info = {\n",
    "    'model_state': model.state_dict(),\n",
    "    'epoch': len(history['train_loss']),\n",
    "    'best_auc': max(history['val_auc']) if history['val_auc'] else 0,\n",
    "    'final_accuracy': history['val_acc'][-1] if history['val_acc'] else 0,\n",
    "    'class_names': class_names,\n",
    "    'image_size': IMG_SIZE,\n",
    "    'normalization': {\n",
    "        'mean': [0.485, 0.456, 0.406],\n",
    "        'std': [0.229, 0.224, 0.225]\n",
    "    }\n",
    "}\n",
    "\n",
    "torch.save(model_info, 'models/pathovision_resnet50_v2.pt')\n",
    "print('✓ Model saved to models/pathovision_resnet50_v2.pt')\n",
    "\n",
    "# Also save the legacy format for compatibility\n",
    "torch.save(model.state_dict(), 'models/pathovision_resnet50_state_dict.pt')\n",
    "print('✓ State dict saved to models/pathovision_resnet50_state_dict.pt')\n",
    "\n",
    "print('\\nModel Information:')\n",
    "print(f'  - Architecture: ResNet50 (ImageNet pretrained)')\n",
    "print(f'  - Training Epochs: {len(history[\"train_loss\"])}')\n",
    "print(f'  - Best Validation AUC: {max(history[\"val_auc\"]):.4f}')\n",
    "print(f'  - Final Test Accuracy: {acc:.4f}')\n",
    "print(f'  - Test AUC-ROC: {roc_auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9305254e",
   "metadata": {},
   "source": [
    "## 12. Simple FastAPI Inference Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5a9d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastAPI inference server - Save as inference_server.py\n",
    "fastapi_code = r'''\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "import uvicorn\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "app = FastAPI(title=\"PathoVision Inference Server\", version=\"2.0\")\n",
    "\n",
    "# Configuration\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "MODEL_PATH = 'models/pathovision_resnet50_v2.pt'\n",
    "IMG_SIZE = 224\n",
    "\n",
    "# Global model variable\n",
    "model = None\n",
    "\n",
    "# Normalization transforms\n",
    "transforms = T.Compose([\n",
    "    T.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def load_model():\n",
    "    \"\"\"Load model on startup\"\"\"\n",
    "    global model\n",
    "    try:\n",
    "        logger.info(f\"Loading model from {MODEL_PATH}\")\n",
    "        checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "        \n",
    "        # Check if it's a full checkpoint with metadata or just state_dict\n",
    "        if isinstance(checkpoint, dict) and 'model_state' in checkpoint:\n",
    "            model_state = checkpoint['model_state']\n",
    "            metadata = {k: v for k, v in checkpoint.items() if k != 'model_state'}\n",
    "            logger.info(f\"Model metadata: {metadata}\")\n",
    "        else:\n",
    "            model_state = checkpoint\n",
    "            logger.warning(\"No metadata found in checkpoint\")\n",
    "        \n",
    "        # Build model (assuming ResNet50)\n",
    "        from torchvision import models\n",
    "        model = models.resnet50(weights=None)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        \n",
    "        # Recreate the custom head\n",
    "        import torch.nn as nn\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(num_ftrs, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.3),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "        \n",
    "        model.load_state_dict(model_state)\n",
    "        model.to(DEVICE)\n",
    "        model.eval()\n",
    "        \n",
    "        logger.info(f\"Model loaded successfully on device: {DEVICE}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load model: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(file: UploadFile = File(...)):\n",
    "    \"\"\"\n",
    "    Predict histopathology image classification\n",
    "    \n",
    "    Args:\n",
    "        file: Image file (PNG, JPG, etc.)\n",
    "    \n",
    "    Returns:\n",
    "        JSON with prediction, confidence, probabilities, and diagnosis\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if model is None:\n",
    "            raise HTTPException(status_code=503, detail=\"Model not loaded\")\n",
    "        \n",
    "        # Read image\n",
    "        image_data = await file.read()\n",
    "        image = Image.open(io.BytesIO(image_data)).convert('RGB')\n",
    "        \n",
    "        # Preprocess\n",
    "        input_tensor = transforms(image).unsqueeze(0).to(DEVICE)\n",
    "        \n",
    "        # Inference with no gradient\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "            probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n",
    "        \n",
    "        pred_idx = int(np.argmax(probs))\n",
    "        confidence = float(probs[pred_idx])\n",
    "        \n",
    "        # Determine diagnosis with confidence threshold\n",
    "        if confidence < 0.60:\n",
    "            diagnosis = \"INCONCLUSIVE - Requires specialist review\"\n",
    "        elif pred_idx == 0:\n",
    "            diagnosis = \"BENIGN - Low malignancy risk\"\n",
    "        else:\n",
    "            diagnosis = \"MALIGNANT - High suspicion, urgent review recommended\"\n",
    "        \n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"prediction\": \"Benign\" if pred_idx == 0 else \"Malignant\",\n",
    "            \"confidence\": confidence,\n",
    "            \"probabilities\": {\n",
    "                \"benign\": float(probs[0]),\n",
    "                \"malignant\": float(probs[1])\n",
    "            },\n",
    "            \"clinical_diagnosis\": diagnosis,\n",
    "            \"timestamp\": str(np.datetime64('now')),\n",
    "            \"model_version\": \"2.0\"\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Prediction error: {str(e)}\")\n",
    "        return JSONResponse(\n",
    "            status_code=500,\n",
    "            content={\"status\": \"error\", \"message\": str(e)}\n",
    "        )\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\n",
    "        \"status\": \"healthy\",\n",
    "        \"model_loaded\": model is not None,\n",
    "        \"device\": str(DEVICE)\n",
    "    }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    uvicorn.run(app, host='0.0.0.0', port=8000, log_level='info')\n",
    "'''\n",
    "\n",
    "# Save the complete API code\n",
    "with open('inference_server.py', 'w') as f:\n",
    "    f.write(fastapi_code)\n",
    "\n",
    "print('✓ FastAPI inference server saved to: inference_server.py')\n",
    "print('\\nTo run the server:')\n",
    "print('  1. pip install fastapi uvicorn pillow torch torchvision')\n",
    "print('  2. python inference_server.py')\n",
    "print('  3. API will be available at http://localhost:8000')\n",
    "print('  4. Swagger docs: http://localhost:8000/docs')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
